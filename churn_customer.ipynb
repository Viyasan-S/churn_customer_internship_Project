{"cells":[{"cell_type":"markdown","metadata":{"id":"dqZ-nhxiganh"},"source":["# **Title of Project**"]},{"cell_type":"markdown","metadata":{"id":"gScHkw6jjrLo"},"source":[" Churn Prediction in Banking"]},{"cell_type":"markdown","metadata":{"id":"Xns_rCdhh-vZ"},"source":["## **Objective**"]},{"cell_type":"markdown","metadata":{"id":"9sPvnFM1iI9l"},"source":["The objective of this project is to predict customer churn in a banking dataset using various machine learning algorithms and identify the best-performing model for future predictions."]},{"cell_type":"markdown","metadata":{"id":"-Vbnt9CciKJP"},"source":["## **Data Source**"]},{"cell_type":"markdown","metadata":{"id":"sGcv5WqQiNyl"},"source":["The dataset used in this project is 'Churn_Modelling.csv.'"]},{"cell_type":"markdown","metadata":{"id":"r7GrZzX0iTlV"},"source":["## **Import Library**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UkK6NH9DiW-X"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import warnings\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import svm\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","import xgboost as xgb\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import joblib\n"]},{"cell_type":"markdown","metadata":{"id":"9lHPQj1XiOUc"},"source":["## **Import Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcU1fdnGho6M"},"outputs":[],"source":["df = pd.read_csv('Churn_Modelling.csv')\n"]},{"cell_type":"markdown","metadata":{"id":"7PUnimBoiX-x"},"source":["## **Describe Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kG15arusiZ8Z"},"outputs":[],"source":["df.info()\n","df.describe(include='all')\n","df.isnull().sum()\n"]},{"cell_type":"markdown","metadata":{"id":"oBGX4Ekniriz"},"source":["## **Data Visualization**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lW-OIRK0iuzO"},"outputs":[],"source":["sns.countplot(df['Exited'])\n"]},{"cell_type":"markdown","metadata":{"id":"UqfyPOCYiiww"},"source":["## **Data Preprocessing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cyr3fbGin0A"},"outputs":[],"source":["df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n","df = pd.get_dummies(df, drop_first=True)\n"]},{"cell_type":"markdown","metadata":{"id":"2jXJpdAuiwYW"},"source":["## **Define Target Variable (y) and Feature Variables (X)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QBCakTuli57t"},"outputs":[],"source":["X = df.drop('Exited', axis=1)\n","y = df['Exited']\n"]},{"cell_type":"markdown","metadata":{"id":"90_0q_Pbi658"},"source":["## **Train Test Split**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u60YYaOFi-Dw"},"outputs":[],"source":["X_res, y_res = SMOTE().fit_resample(X, y)\n","X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=47)\n"]},{"cell_type":"markdown","metadata":{"id":"cIhyseNria7W"},"source":["## **Modeling**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Toq58wpkjCw7"},"outputs":[],"source":["sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Logistic Regression\n","log = LogisticRegression()\n","log.fit(X_train, y_train)\n","\n","# SVM\n","svm_model = svm.SVC()\n","svm_model.fit(X_train, y_train)\n","\n","# KNeighbors Classifier\n","knn = KNeighborsClassifier()\n","knn.fit(X_train, y_train)\n","\n","# Decision Tree Classifier\n","dt = DecisionTreeClassifier()\n","dt.fit(X_train, y_train)\n","\n","# Random Forest Classifier\n","rf = RandomForestClassifier()\n","rf.fit(X_train, y_train)\n","\n","# Gradient Boosting Classifier\n","gbc = GradientBoostingClassifier()\n","gbc.fit(X_train, y_train)\n","\n","# XGBoost\n","model_xgb = xgb.XGBClassifier(random_state=42, verbosity=0)\n","model_xgb.fit(X_train, y_train)\n"]},{"cell_type":"markdown","metadata":{"id":"vhAwWfG0jFun"},"source":["## **Model Evaluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lND3jJj_jhx4"},"outputs":[],"source":["# Evaluation Metrics\n","def evaluate_model(model, X_test, y_test):\n","    y_pred = model.predict(X_test)\n","    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n","    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n","    print(f\"Recall: {recall_score(y_test, y_pred)}\")\n","    print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n","\n","# Evaluate Models\n","evaluate_model(log, X_test, y_test)\n","evaluate_model(svm_model, X_test, y_test)\n","evaluate_model(knn, X_test, y_test)\n","evaluate_model(dt, X_test, y_test)\n","evaluate_model(rf, X_test, y_test)\n","evaluate_model(gbc, X_test, y_test)\n","evaluate_model(model_xgb, X_test, y_test)\n"]},{"cell_type":"markdown","metadata":{"id":"8AzwG7oLjiQI"},"source":["## **Prediction**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JLebGzDJjknA"},"outputs":[],"source":["# Save the best model (XGBoost)\n","model_xgb.fit(X_res, y_res)\n","joblib.dump(model_xgb, 'churn_predict_model')\n","model = joblib.load('churn_predict_model')\n"]},{"cell_type":"markdown","metadata":{"id":"SBo38CJZjlEX"},"source":["## **Explaination**"]},{"cell_type":"markdown","metadata":{"id":"Ybi8FR9Kjv00"},"source":["The project focuses on predicting customer churn in a banking dataset. After importing the necessary libraries and loading the data, irrelevant features are dropped, and categorical data is encoded. The target variable (Exited) and feature variables are defined, and the dataset is split into training and testing sets. To address imbalanced data, the Synthetic Minority Over-sampling Technique (SMOTE) is applied.\n","\n","Several machine learning models, including Logistic Regression, SVM, KNeighbors Classifier, Decision Tree Classifier, Random Forest Classifier, Gradient Boosting Classifier, and XGBoost, are trained and evaluated using accuracy, precision, recall, and F1 score metrics. The XGBoost classifier is identified as the best-performing model based on accuracy.\n","\n","Finally, the best model (XGBoost) is saved for future predictions."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPZl4d0nA5Qmq8X1mDqSb1O","name":"Project Outline.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
